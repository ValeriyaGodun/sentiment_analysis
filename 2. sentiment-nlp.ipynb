{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c129e3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Устанавливаем дополнительные библиотеки, которых нет в стандартной среде Kaggle\n",
    "!pip install clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aac4c9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Настраиваем окружение ClearML\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=''\n",
    "%env CLEARML_API_SECRET_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f620a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:35:13.166407Z",
     "iopub.status.busy": "2025-10-28T15:35:13.165668Z",
     "iopub.status.idle": "2025-10-28T15:35:32.654215Z",
     "shell.execute_reply": "2025-10-28T15:35:32.653556Z",
     "shell.execute_reply.started": "2025-10-28T15:35:13.166367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import List, Dict, Callable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from clearml import Task, Logger, Dataset\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80cb45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:37:26.647381Z",
     "iopub.status.busy": "2025-10-28T15:37:26.646090Z",
     "iopub.status.idle": "2025-10-28T15:37:26.688925Z",
     "shell.execute_reply": "2025-10-28T15:37:26.688197Z",
     "shell.execute_reply.started": "2025-10-28T15:37:26.647347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Централизованная конфигурация для всего пайплайна\n",
    "class Config:\n",
    "\n",
    "    # Общие\n",
    "    SEED = 42\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Данные\n",
    "    TEST_SIZE = 0.2\n",
    "    MAX_LEN = 64 \n",
    "    \n",
    "    # Токенизация\n",
    "    VOCAB_SIZE = 20000  \n",
    "    EMBEDDING_DIM = 100\n",
    "    \n",
    "    # Word2Vec\n",
    "    W2V_WINDOW = 5\n",
    "    W2V_MIN_COUNT = 2\n",
    "    W2V_WORKERS = 4\n",
    "    W2V_EPOCHS = 5\n",
    "    \n",
    "    # Параметрв модели\n",
    "    HIDDEN_SIZE = 96 \n",
    "    BANK_EMBED_DIM = 12  \n",
    "    DROPOUT = 0.55 \n",
    "    NUM_CLASSES = 3\n",
    "    GRU_LAYERS = 1  \n",
    "    \n",
    "    # Обучение\n",
    "    BATCH_SIZE = 32\n",
    "    BANKS_EPOCHS = 15\n",
    "    SENTIMENT_EPOCHS = 13  \n",
    "    LEARNING_RATE = 1e-3 \n",
    "    LEARNING_RATE_BA = 1.5e-4  \n",
    "    GRADIENT_CLIP = 0.3  \n",
    "    WEIGHT_DECAY = 1.5e-2  \n",
    "\n",
    "    # Инференс\n",
    "    BANK_THRESHOLD = 0.2\n",
    "    \n",
    "    # Банки и метки\n",
    "    BANK_TARGETS = ['sber', 'vtb', 'gazprom', 'alfabank', 'raiffeisen', 'rshb', 'company']\n",
    "    SENTIMENT_LABELS = {-1: 0, 0: 1, 1: 2}\n",
    "    LABELS_TO_SENTIMENT = {0: -1, 1: 0, 2: 1}\n",
    "    \n",
    "    # Специальные токены\n",
    "    SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "\n",
    "\n",
    "# Фиксация сидов для воспроизводимости\n",
    "def set_seed(seed: int = Config.SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ed93c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:37:29.531431Z",
     "iopub.status.busy": "2025-10-28T15:37:29.530635Z",
     "iopub.status.idle": "2025-10-28T15:37:29.535863Z",
     "shell.execute_reply": "2025-10-28T15:37:29.535127Z",
     "shell.execute_reply.started": "2025-10-28T15:37:29.531401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Проверка устройства\n",
    "device = torch.device(Config.DEVICE)\n",
    "print(f\"Используется устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ecf0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:37:32.415050Z",
     "iopub.status.busy": "2025-10-28T15:37:32.414358Z",
     "iopub.status.idle": "2025-10-28T15:37:34.497725Z",
     "shell.execute_reply": "2025-10-28T15:37:34.496994Z",
     "shell.execute_reply.started": "2025-10-28T15:37:32.415015Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Находим датасет в ClearML\n",
    "dataset = Dataset.get('2a542c96a0de46b0bc8b4977bf536180')\n",
    "print(dataset.list_files())\n",
    "\n",
    "# Скачиваем датасет в локальный кеш, чтобы дальше работать с файлами как с обычными CSV\n",
    "local_path = dataset.get_local_copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316013e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:37:38.336923Z",
     "iopub.status.busy": "2025-10-28T15:37:38.336151Z",
     "iopub.status.idle": "2025-10-28T15:37:38.407089Z",
     "shell.execute_reply": "2025-10-28T15:37:38.406216Z",
     "shell.execute_reply.started": "2025-10-28T15:37:38.336895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Читаем обучающую выборку\n",
    "orig_df = pd.read_csv(f'{local_path}/train.csv',sep=\";\",quoting=csv.QUOTE_NONE, na_values=['NULL'])\n",
    "orig_df['text'] = orig_df['text'].fillna('')\n",
    "orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd00308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:37:47.215800Z",
     "iopub.status.busy": "2025-10-28T15:37:47.215512Z",
     "iopub.status.idle": "2025-10-28T15:37:53.040655Z",
     "shell.execute_reply": "2025-10-28T15:37:53.039225Z",
     "shell.execute_reply.started": "2025-10-28T15:37:47.215781Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Инициализируем удаленную таску\n",
    "task = Task.init(\n",
    "        project_name=\"sentiment_analysis_kaggle_mllabs\",\n",
    "        task_name=\"two_GRU_models_final\",\n",
    "        task_type=\"training\",\n",
    ")\n",
    "task:Task\n",
    "\n",
    "# Получаем логгер для последующего логирования метрик и артефактов\n",
    "log = Logger.current_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d6e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:38:47.596047Z",
     "iopub.status.busy": "2025-10-28T15:38:47.593898Z",
     "iopub.status.idle": "2025-10-28T15:38:47.619980Z",
     "shell.execute_reply": "2025-10-28T15:38:47.619139Z",
     "shell.execute_reply.started": "2025-10-28T15:38:47.595993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Разбиваем на train/test\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    orig_df,\n",
    "    test_size=Config.TEST_SIZE,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "print(f\"Train: {len(train_df)} примеров, Test: {len(test_df)} примеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549227e8-134f-4b94-9fb0-303c499b2bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:38:57.473498Z",
     "iopub.status.busy": "2025-10-28T15:38:57.473047Z",
     "iopub.status.idle": "2025-10-28T15:39:00.223559Z",
     "shell.execute_reply": "2025-10-28T15:39:00.222580Z",
     "shell.execute_reply.started": "2025-10-28T15:38:57.473472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Разведочный анализ: сначала смотрим длину текстов, чтобы настраивать MAX_LEN\n",
    "orig_text_len = orig_df['text'].astype(str).str.len()\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(orig_text_len, bins=60, kde=True, color=\"#4c72b0\")\n",
    "plt.title(\"Длина текстов — исходные данные\")\n",
    "plt.xlabel(\"Символы\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Проверяем, насколько распределение банков сопоставимо между train/val\n",
    "banks = Config.BANK_TARGETS\n",
    "train_counts = train_df[banks].notna().sum().reindex(banks).astype(int)\n",
    "val_counts   = test_df[banks].notna().sum().reindex(banks).astype(int)\n",
    "\n",
    "bar_df = pd.DataFrame({\n",
    "    \"bank\": banks,\n",
    "    \"train\": train_counts.values,\n",
    "    \"val\": val_counts.values,\n",
    "}).melt(id_vars=[\"bank\"], value_vars=[\"train\", \"val\"],\n",
    "       var_name=\"split\", value_name=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    data=bar_df, x=\"bank\", y=\"count\", hue=\"split\",\n",
    "    hue_order=[\"train\", \"val\"],\n",
    "    palette={\"train\": \"#4c72b0\", \"val\": \"#dd8452\"},\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.legend([\"train\", \"val\"], title=\"split\")\n",
    "ax.set_title(\"Частота упоминаний (train vs val)\")\n",
    "ax.set_xlabel(\"банк\")\n",
    "ax.set_ylabel(\"число упоминаний\")\n",
    "plt.xticks(rotation=20)\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Для каждой компании смотрим баланс классов сентимента\n",
    "rows = []\n",
    "for b in banks:\n",
    "    s = train_df[train_df[b].notna()][b]\n",
    "    rows.append({\n",
    "        \"bank\": b,\n",
    "        \"negative\": (s == -1).sum(),\n",
    "        \"neutral\": (s == 0).sum(),\n",
    "        \"positive\": (s == 1).sum(),\n",
    "        \"total\": len(s)\n",
    "    })\n",
    "stat_df = pd.DataFrame(rows)\n",
    "long_df = stat_df.melt(id_vars=[\"bank\", \"total\"], value_vars=[\"negative\", \"neutral\", \"positive\"],\n",
    "                       var_name=\"sentiment\", value_name=\"count\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "base = pd.pivot_table(long_df, index=\"bank\", columns=\"sentiment\", values=\"count\", fill_value=0)\n",
    "base = base[[\"negative\", \"neutral\", \"positive\"]]\n",
    "base.div(base.sum(axis=1), axis=0).plot(kind=\"bar\", stacked=True, ax=ax,\n",
    "                                        color=[\"#c44e52\", \"#dd8452\", \"#55a868\"])\n",
    "ax.set_title(\"Доля классов сентимента по банкам (train)\")\n",
    "ax.set_xlabel(\"банк\")\n",
    "ax.set_ylabel(\"доля\")\n",
    "plt.xticks(rotation=20)\n",
    "plt.legend(title=\"sentiment\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Строим матрицу со-встречаемости, чтобы понять, кого часто упоминают вместе\n",
    "cooc = pd.DataFrame(0, index=banks, columns=banks, dtype=int)\n",
    "train_presence = train_df[banks].notna().astype(int).values\n",
    "for i, bi in enumerate(banks):\n",
    "    for j, bj in enumerate(banks):\n",
    "        if j >= i:\n",
    "            cooc.iloc[i, j] = int((train_presence[:, i] & train_presence[:, j]).sum())\n",
    "            cooc.iloc[j, i] = cooc.iloc[i, j]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cooc, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Со-встречаемость упоминаний банков (train)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Наконец, оцениваем общий дисбаланс тональностей, чтобы подобрать веса\n",
    "sentiment_map = {-1: \"negative\", 0: \"neutral\", 1: \"positive\"}\n",
    "all_labels = []\n",
    "for b in banks:\n",
    "    s = train_df[train_df[b].notna()][b]\n",
    "    all_labels.extend(s.values.tolist())\n",
    "all_labels = pd.Series(all_labels)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "sns.countplot(x=all_labels.map(sentiment_map), order=[\"negative\", \"neutral\", \"positive\"],\n",
    "              palette=[\"#c44e52\", \"#dd8452\", \"#55a868\"], ax=ax)\n",
    "ax.set_title(\"Общий дисбаланс сентимента (train, агрегировано по банкам)\")\n",
    "ax.set_xlabel(\"sentiment\")\n",
    "ax.set_ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1db36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:10.430863Z",
     "iopub.status.busy": "2025-10-28T15:39:10.430022Z",
     "iopub.status.idle": "2025-10-28T15:39:10.437176Z",
     "shell.execute_reply": "2025-10-28T15:39:10.436182Z",
     "shell.execute_reply.started": "2025-10-28T15:39:10.430833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Выполняем токенизацию и предобработку\n",
    "\n",
    "CLEANUP_PATTERN = re.compile(r\"[0-9!#$%&'()*+,./:;<=>?[\\\\]^_`{|}~—\\\"\\-]+\")\n",
    "\n",
    "# Обучаем WordPiece токенизатор на корпусе текстов\n",
    "def train_wordpiece_tokenizer(texts: List[str], vocab_size: int = Config.VOCAB_SIZE) -> Tokenizer:\n",
    "\n",
    "    tok = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "    tok.pre_tokenizer = Whitespace()\n",
    "    trainer = WordPieceTrainer(\n",
    "        vocab_size=vocab_size, \n",
    "        special_tokens=Config.SPECIAL_TOKENS\n",
    "    )\n",
    "    tok.train_from_iterator(texts, trainer)\n",
    "    return tok\n",
    "\n",
    "# Токенизируем текст с предварительной очисткой\n",
    "def wp_tokenize(text: str, tokenizer: Tokenizer) -> List[str]:\n",
    "    clean = CLEANUP_PATTERN.sub(\" \", str(text).lower())\n",
    "    return tokenizer.encode(clean).tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c98091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:14.759162Z",
     "iopub.status.busy": "2025-10-28T15:39:14.758539Z",
     "iopub.status.idle": "2025-10-28T15:39:17.174485Z",
     "shell.execute_reply": "2025-10-28T15:39:17.173682Z",
     "shell.execute_reply.started": "2025-10-28T15:39:14.759140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Собираем тексты\n",
    "all_texts = pd.concat([train_df['text'], test_df['text']], axis=0).astype(str).tolist()\n",
    "\n",
    "# Обучаем токенизатор\n",
    "wp_tokenizer = train_wordpiece_tokenizer(all_texts, vocab_size=Config.VOCAB_SIZE)\n",
    "print(f\"Токенизатор обучен. Размер словаря: {wp_tokenizer.get_vocab_size()}\")\n",
    "\n",
    "# Токенизация для Word2Vec\n",
    "sentences = [wp_tokenize(t, wp_tokenizer) for t in all_texts]\n",
    "\n",
    "# Обучаем Word2Vec\n",
    "w2v = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    vector_size=Config.EMBEDDING_DIM, \n",
    "    window=Config.W2V_WINDOW, \n",
    "    min_count=Config.W2V_MIN_COUNT, \n",
    "    workers=Config.W2V_WORKERS, \n",
    "    sg=1, \n",
    "    epochs=Config.W2V_EPOCHS\n",
    ")\n",
    "print(f\"Word2Vec обучен. Векторов в модели: {len(w2v.wv)}\")\n",
    "\n",
    "# Извлекаем ID специальных токенов\n",
    "pad_id = wp_tokenizer.token_to_id(\"[PAD]\")\n",
    "cls_id = wp_tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_id = wp_tokenizer.token_to_id(\"[SEP]\")\n",
    "vocab_size = wp_tokenizer.get_vocab_size()\n",
    "\n",
    "# Создаём матрицу эмбеддингов\n",
    "embedding_matrix = np.random.normal(0, 0.02, size=(vocab_size, Config.EMBEDDING_DIM)).astype(np.float32)\n",
    "\n",
    "# Заполняем векторами из Word2Vec\n",
    "w2v_coverage = 0\n",
    "for token, idx in wp_tokenizer.get_vocab().items():\n",
    "    if token in w2v.wv:\n",
    "        embedding_matrix[idx] = w2v.wv[token]\n",
    "        w2v_coverage += 1\n",
    "\n",
    "# Zero-вектор для PAD\n",
    "if pad_id is not None:\n",
    "    embedding_matrix[pad_id] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7b82d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:20.535618Z",
     "iopub.status.busy": "2025-10-28T15:39:20.535266Z",
     "iopub.status.idle": "2025-10-28T15:39:20.547007Z",
     "shell.execute_reply": "2025-10-28T15:39:20.546111Z",
     "shell.execute_reply.started": "2025-10-28T15:39:20.535596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем функцию для кодирования текста в последовательность токенов с [CLS] и [SEP]\n",
    "def encode_text(text: str) -> List[int]:\n",
    "    clean = CLEANUP_PATTERN.sub(\" \", str(text).lower())\n",
    "    encoding = wp_tokenizer.encode(clean)\n",
    "    ids = [cls_id] + encoding.ids[:Config.MAX_LEN-2] + [sep_id]\n",
    "    if len(ids) < Config.MAX_LEN:\n",
    "        ids = ids + [pad_id] * (Config.MAX_LEN - len(ids))  # Паддингом выравниваем батчи внутри DataLoader\n",
    "    return ids[:Config.MAX_LEN]\n",
    "\n",
    "# Датасет для определения упомянутых банков (multi-label classification)\n",
    "class BanksDataset(TorchDataset):\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.texts = df['text'].values\n",
    "        # Предварительно извлекаем все метки банков\n",
    "        self.labels = df[Config.BANK_TARGETS].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        x = torch.tensor(encode_text(text), dtype=torch.long)\n",
    "        # Преобразуем в 0 или 1\n",
    "        y = torch.tensor([1 if pd.notna(l) else 0 for l in labels], dtype=torch.float32)\n",
    "        return x, y \n",
    "\n",
    "# Датасет для классификации сентимента\n",
    "class BankAwareSentimentDataset(TorchDataset):\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.data = []\n",
    "        \n",
    "        for bank_idx, bank_name in enumerate(Config.BANK_TARGETS):\n",
    "            mask = df[bank_name].notna()\n",
    "            if mask.sum() > 0:\n",
    "                bank_df = df[mask]\n",
    "                for text, sentiment in zip(bank_df['text'].values, bank_df[bank_name].values):\n",
    "                    self.data.append((\n",
    "                        text, \n",
    "                        bank_idx, \n",
    "                        Config.SENTIMENT_LABELS[int(sentiment)]\n",
    "                    )) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        text, bank_idx, label = self.data[idx]\n",
    "        x = torch.tensor(encode_text(text), dtype=torch.long)\n",
    "        bank = torch.tensor(bank_idx, dtype=torch.long)\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        return x, bank, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce7ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:24.042586Z",
     "iopub.status.busy": "2025-10-28T15:39:24.041868Z",
     "iopub.status.idle": "2025-10-28T15:39:24.264901Z",
     "shell.execute_reply": "2025-10-28T15:39:24.263943Z",
     "shell.execute_reply.started": "2025-10-28T15:39:24.042548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем модели\n",
    "\n",
    "# Multi-label классификатор для определения упомянутых банков\n",
    "class GRUMultiLabel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_size: int, \n",
    "                 num_labels: int, embedding_matrix: np.ndarray, \n",
    "                 dropout: float = Config.DROPOUT):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_id)\n",
    "        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix))  # Стартуем с предобученных W2V весов\n",
    "        self.embedding.weight.requires_grad = True  # Разрешаем дальнейшее дообучение под задачу\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        emb = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        out, _ = self.gru(emb)  # (batch_size, seq_len, hidden_size*2)\n",
    "        lengths = (x != pad_id).sum(dim=1) - 1  # (batch_size,) - берём эмбеддинг последнего непаддингового токена\n",
    "        h = out[torch.arange(out.size(0)), lengths, :]  # (batch_size, hidden_size*2)\n",
    "        h = self.dropout(h)\n",
    "        logits = self.fc(h)  # (batch_size, num_labels)\n",
    "        return logits\n",
    "\n",
    "# Классификатор сентимента\n",
    "class BankAwareGRUClassifier(nn.Module):\n",
    "   \n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_size: int, \n",
    "                 num_classes: int, num_banks: int, bank_embed_dim: int, \n",
    "                 embedding_matrix: np.ndarray, dropout: float = Config.DROPOUT):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_id)\n",
    "        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix))  \n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.emb_dropout = nn.Dropout(0.2) \n",
    "        self.bank_embedding = nn.Embedding(num_banks, bank_embed_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, num_layers=Config.GRU_LAYERS, \n",
    "                         batch_first=True, bidirectional=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2 + bank_embed_dim, num_classes)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def forward(self, x, bank_idx):\n",
    "        # x: (batch_size, seq_len)\n",
    "        # bank_idx: (batch_size,)\n",
    "        emb = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        emb = self.emb_dropout(emb)\n",
    "\n",
    "        out, _ = self.gru(emb)  # (batch_size, seq_len, hidden_size*2)\n",
    "        mask = (x != pad_id).unsqueeze(-1).float()  # (batch_size, seq_len, 1)\n",
    "        masked_out = out * mask  # (batch_size, seq_len, hidden_size*2)\n",
    "        sum_out = masked_out.sum(dim=1)  # (batch_size, hidden_size*2)\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (batch_size, 1)\n",
    "\n",
    "        h = sum_out / lengths  # (batch_size, hidden_size*2)\n",
    "        h = self.batch_norm(h)\n",
    "        h = self.dropout(h)\n",
    "\n",
    "        bank_emb = self.bank_embedding(bank_idx)  # (batch_size, bank_embed_dim)\n",
    "        combined = torch.cat([h, bank_emb], dim=1)  # (batch_size, hidden_size*2 + bank_embed_dim)\n",
    "        logits = self.fc(combined)  # (batch_size, num_classes)\n",
    "        \n",
    "        return logits \n",
    "\n",
    "banks_model = GRUMultiLabel(\n",
    "    vocab_size=vocab_size, \n",
    "    embed_dim=Config.EMBEDDING_DIM, \n",
    "    hidden_size=Config.HIDDEN_SIZE, \n",
    "    num_labels=len(Config.BANK_TARGETS), \n",
    "    embedding_matrix=embedding_matrix\n",
    ")\n",
    "\n",
    "sentiment_model_ba = BankAwareGRUClassifier(\n",
    "    vocab_size=vocab_size, \n",
    "    embed_dim=Config.EMBEDDING_DIM, \n",
    "    hidden_size=Config.HIDDEN_SIZE, \n",
    "    num_classes=Config.NUM_CLASSES, \n",
    "    num_banks=len(Config.BANK_TARGETS), \n",
    "    bank_embed_dim=Config.BANK_EMBED_DIM, \n",
    "    embedding_matrix=embedding_matrix\n",
    ")\n",
    "\n",
    "banks_model.to(device)\n",
    "sentiment_model_ba.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e66596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:31.069336Z",
     "iopub.status.busy": "2025-10-28T15:39:31.068531Z",
     "iopub.status.idle": "2025-10-28T15:39:31.076898Z",
     "shell.execute_reply": "2025-10-28T15:39:31.076155Z",
     "shell.execute_reply.started": "2025-10-28T15:39:31.069302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Подсчёт параметров моделей\n",
    "banks_params = sum(p.numel() for p in banks_model.parameters() if p.requires_grad)\n",
    "sentiment_params = sum(p.numel() for p in sentiment_model_ba.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Banks Model: {banks_params:,} параметров\")\n",
    "print(f\"Sentiment Model: {sentiment_params:,} параметров\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bf088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:37.120387Z",
     "iopub.status.busy": "2025-10-28T15:39:37.119468Z",
     "iopub.status.idle": "2025-10-28T15:39:37.128648Z",
     "shell.execute_reply": "2025-10-28T15:39:37.127654Z",
     "shell.execute_reply.started": "2025-10-28T15:39:37.120349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем функции для подсчета метрик\n",
    "\n",
    "# Macro F1 для multi-label классификации. Вычисляет F1 для каждого класса и усредняет.\n",
    "def macro_f1_multi_label(y_true: np.ndarray, y_pred_logits: np.ndarray, \n",
    "                         threshold: float = Config.BANK_THRESHOLD) -> float:\n",
    "\n",
    "    y_pred = (1/(1+np.exp(-y_pred_logits)) >= threshold).astype(int)\n",
    "    per_label = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        per_label.append(f1_score(y_true[:, i], y_pred[:, i], zero_division=0))\n",
    "    return float(np.mean(per_label))\n",
    "\n",
    "# Macro F1 для multiclass классификации\n",
    "def macro_f1_multiclass(y_true: np.ndarray, y_pred_logits: np.ndarray) -> float:\n",
    "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "    return float(f1_score(y_true, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ecb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:42.509466Z",
     "iopub.status.busy": "2025-10-28T15:39:42.508643Z",
     "iopub.status.idle": "2025-10-28T15:39:42.522869Z",
     "shell.execute_reply": "2025-10-28T15:39:42.521783Z",
     "shell.execute_reply.started": "2025-10-28T15:39:42.509441Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем функции для обучения\n",
    "\n",
    "# Универсальная функция для одной эпохи обучения/валидации\n",
    "def _run_epoch(model, loader, criterion, optimizer=None, \n",
    "               metric_fn: Callable = None, is_bank_aware: bool = False):\n",
    "\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_true, all_logits = [], []\n",
    "    \n",
    "    context = torch.no_grad() if not is_train else torch.enable_grad() \n",
    "    \n",
    "    with context:\n",
    "        for batch in tqdm(loader):\n",
    "            if is_bank_aware:\n",
    "                x, bank_idx, y = batch\n",
    "                x = x.to(device)\n",
    "                bank_idx = bank_idx.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                if is_train:\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                logits = model(x, bank_idx)\n",
    "            else:\n",
    "                x, y = batch\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                if is_train:\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                logits = model(x)\n",
    "            \n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            all_true.append(y.detach().cpu().numpy())\n",
    "            all_logits.append(logits.detach().cpu().numpy())  # Сохраняем логицы для последующего расчёта F1\n",
    "    \n",
    "    y_true = np.concatenate(all_true, axis=0)\n",
    "    y_logits = np.concatenate(all_logits, axis=0)\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    metric = metric_fn(y_true, y_logits) if metric_fn else 0.0\n",
    "    \n",
    "    return avg_loss, metric\n",
    "\n",
    "\n",
    "# Обёртки для удобства\n",
    "\n",
    "# Эпоха обучения модели определения банков\n",
    "def train_epoch_banks(model, loader, optimizer, criterion):\n",
    "    return _run_epoch(model, loader, criterion, optimizer, \n",
    "                     metric_fn=macro_f1_multi_label, is_bank_aware=False)\n",
    "\n",
    "\n",
    "# Эпоха валидации модели определения банков\n",
    "def eval_epoch_banks(model, loader, criterion):\n",
    "    return _run_epoch(model, loader, criterion, optimizer=None, \n",
    "                     metric_fn=macro_f1_multi_label, is_bank_aware=False)\n",
    "\n",
    "\n",
    "# Эпоха обучения модели сентимента с градиентным клиппингом\n",
    "def train_epoch_sent_ba(model, loader, optimizer, criterion):\n",
    "    is_train = True\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_true, all_logits = [], []\n",
    "    \n",
    "    for batch in tqdm(loader):\n",
    "        x, bank_idx, y = batch\n",
    "        x = x.to(device)\n",
    "        bank_idx = bank_idx.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(x, bank_idx)\n",
    "        loss = criterion(logits, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Градиентный клиппинг для стабильности\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), Config.GRADIENT_CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        all_true.append(y.detach().cpu().numpy())\n",
    "        all_logits.append(logits.detach().cpu().numpy())  # F1 считаем уже на CPU, чтобы не тратить GPU память\n",
    "    \n",
    "    y_true = np.concatenate(all_true, axis=0)\n",
    "    y_logits = np.concatenate(all_logits, axis=0)\n",
    "    \n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    metric = macro_f1_multiclass(y_true, y_logits)\n",
    "    \n",
    "    return avg_loss, metric\n",
    "\n",
    "# Эпоха валидации модели сентимента\n",
    "def eval_epoch_sent_ba(model, loader, criterion):\n",
    "\n",
    "    return _run_epoch(model, loader, criterion, optimizer=None, \n",
    "                     metric_fn=macro_f1_multiclass, is_bank_aware=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072d93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:47.672924Z",
     "iopub.status.busy": "2025-10-28T15:39:47.672621Z",
     "iopub.status.idle": "2025-10-28T15:39:47.685036Z",
     "shell.execute_reply": "2025-10-28T15:39:47.684006Z",
     "shell.execute_reply.started": "2025-10-28T15:39:47.672903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем датасеты для модели определения банков\n",
    "\n",
    "train_banks_ds = BanksDataset(train_df)\n",
    "val_banks_ds = BanksDataset(test_df)\n",
    "\n",
    "train_banks_loader = DataLoader(\n",
    "    train_banks_ds, \n",
    "    batch_size=Config.BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "val_banks_loader = DataLoader(\n",
    "    val_banks_ds, \n",
    "    batch_size=Config.BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_banks_ds)} примеров, {len(train_banks_loader)} батчей\")\n",
    "print(f\"Val: {len(val_banks_ds)} примеров, {len(val_banks_loader)} батчей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726aaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:39:54.015185Z",
     "iopub.status.busy": "2025-10-28T15:39:54.014529Z",
     "iopub.status.idle": "2025-10-28T15:40:46.295586Z",
     "shell.execute_reply": "2025-10-28T15:40:46.294812Z",
     "shell.execute_reply.started": "2025-10-28T15:39:54.015159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Обучаем модель определения банков\n",
    "\n",
    "banks_criterion = nn.BCEWithLogitsLoss() \n",
    "banks_optimizer = torch.optim.Adam(banks_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(1, Config.BANKS_EPOCHS + 1):\n",
    "    tr_loss, tr_f1 = train_epoch_banks(banks_model, train_banks_loader, banks_optimizer, banks_criterion)\n",
    "    val_loss, val_f1 = eval_epoch_banks(banks_model, val_banks_loader, banks_criterion)\n",
    "    \n",
    "    print(f\"[Эпоха {epoch}/{Config.BANKS_EPOCHS}] \"\n",
    "          f\"Train: loss={tr_loss:.4f}, F1={tr_f1:.4f} | \"\n",
    "          f\"Val: loss={val_loss:.4f}, F1={val_f1:.4f}\")\n",
    "    \n",
    "    # Логирование в ClearML\n",
    "    log.report_scalar(title='Banks Loss', series='train', value=tr_loss, iteration=epoch)\n",
    "    log.report_scalar(title='Banks Loss', series='val', value=val_loss, iteration=epoch)\n",
    "    log.report_scalar(title='Banks F1', series='train', value=tr_f1, iteration=epoch)\n",
    "    log.report_scalar(title='Banks F1', series='val', value=val_f1, iteration=epoch)\n",
    "    \n",
    "    # Сохраняем лучшую модель\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(banks_model.state_dict(), \"banks_model_best.pt\")\n",
    "\n",
    "print(f\"Обучение модели банков завершено. Лучший Val F1: {best_val_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2660e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:56:15.742561Z",
     "iopub.status.busy": "2025-10-28T15:56:15.741869Z",
     "iopub.status.idle": "2025-10-28T15:56:15.765570Z",
     "shell.execute_reply": "2025-10-28T15:56:15.764850Z",
     "shell.execute_reply.started": "2025-10-28T15:56:15.742537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создаем датасеты для модели определения сентимента\n",
    "\n",
    "train_ba_ds = BankAwareSentimentDataset(train_df)\n",
    "val_ba_ds = BankAwareSentimentDataset(test_df)\n",
    "\n",
    "train_ba_loader = DataLoader(\n",
    "    train_ba_ds, \n",
    "    batch_size=Config.BATCH_SIZE, \n",
    "    shuffle=True,  \n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "val_ba_loader = DataLoader(\n",
    "    val_ba_ds, \n",
    "    batch_size=Config.BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_ba_ds)} примеров, {len(train_ba_loader)} батчей\")\n",
    "print(f\"Val: {len(val_ba_ds)} примеров, {len(val_ba_loader)} батчей\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204928f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:56:18.861880Z",
     "iopub.status.busy": "2025-10-28T15:56:18.861172Z",
     "iopub.status.idle": "2025-10-28T15:57:06.217693Z",
     "shell.execute_reply": "2025-10-28T15:57:06.216746Z",
     "shell.execute_reply.started": "2025-10-28T15:56:18.861844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Обучаем модель определения сентимента с классовыми весами\n",
    "\n",
    "# Рассчитываем веса классов для борьбы с дисбалансом\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "all_sentiments = []\n",
    "for bank in Config.BANK_TARGETS:\n",
    "    bank_data = train_df[train_df[bank].notna()][bank].values\n",
    "    all_sentiments.extend([Config.SENTIMENT_LABELS[int(s)] for s in bank_data])  # Приводим метки к {0,1,2}, как ожидает CrossEntropy\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.array([0, 1, 2]),\n",
    "    y=np.array(all_sentiments)\n",
    ")\n",
    "\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "print(f\"Class weights: neg={class_weights[0]:.2f}, neu={class_weights[1]:.2f}, pos={class_weights[2]:.2f}\")\n",
    "\n",
    "sent_ba_criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "sentiment_ba_optim = torch.optim.AdamW(\n",
    "    sentiment_model_ba.parameters(), \n",
    "    lr=Config.LEARNING_RATE_BA, \n",
    "    weight_decay=Config.WEIGHT_DECAY,  \n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Добавляем ReduceLROnPlateau scheduler для адаптивного снижения learning rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    sentiment_ba_optim, mode='max', factor=0.5, patience=2, min_lr=1e-6\n",
    ")  \n",
    "\n",
    "best_sent_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(1, Config.SENTIMENT_EPOCHS + 1):\n",
    "    tr_loss, tr_f1 = train_epoch_sent_ba(sentiment_model_ba, train_ba_loader, sentiment_ba_optim, sent_ba_criterion)\n",
    "    val_loss, val_f1 = eval_epoch_sent_ba(sentiment_model_ba, val_ba_loader, sent_ba_criterion)\n",
    "    \n",
    "    # Обновляем scheduler\n",
    "    scheduler.step(val_f1)\n",
    "    current_lr = sentiment_ba_optim.param_groups[0]['lr']  # Быстро контролирую, насколько scheduler «подрезал» шаг\n",
    "    \n",
    "    print(f\"[Эпоха {epoch}/{Config.SENTIMENT_EPOCHS}] \"\n",
    "          f\"Train: loss={tr_loss:.4f}, F1={tr_f1:.4f} | \"\n",
    "          f\"Val: loss={val_loss:.4f}, F1={val_f1:.4f} | \"\n",
    "          f\"LR={current_lr:.6f}\")\n",
    "    \n",
    "    # Логирование в ClearML\n",
    "    log.report_scalar(title='Sentiment Loss', series='train', value=tr_loss, iteration=epoch)\n",
    "    log.report_scalar(title='Sentiment Loss', series='val', value=val_loss, iteration=epoch)\n",
    "    log.report_scalar(title='Sentiment F1', series='train', value=tr_f1, iteration=epoch)\n",
    "    log.report_scalar(title='Sentiment F1', series='val', value=val_f1, iteration=epoch)\n",
    "    log.report_scalar(title='Learning Rate', series='sentiment', value=current_lr, iteration=epoch)\n",
    "    \n",
    "    # Сохраняем лучшую модель\n",
    "    if val_f1 > best_sent_val_f1:\n",
    "        best_sent_val_f1 = val_f1\n",
    "        torch.save(sentiment_model_ba.state_dict(), \"sentiment_best_model.pt\")  # Сохраняем чекпоинт под Kaggle Submission\n",
    "\n",
    "print(f\"Обучение модели сентимента завершено. Лучший Val F1: {best_sent_val_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3433c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:57:09.715765Z",
     "iopub.status.busy": "2025-10-28T15:57:09.714975Z",
     "iopub.status.idle": "2025-10-28T15:57:10.968430Z",
     "shell.execute_reply": "2025-10-28T15:57:10.967693Z",
     "shell.execute_reply.started": "2025-10-28T15:57:09.715741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Полный пайплайн: определяем банки в тексте и для каждого найденного банка определяем сентимент\n",
    "\n",
    "banks_model.eval()\n",
    "sentiment_model_ba.eval()\n",
    "\n",
    "# Собираем результаты по банкам\n",
    "bank_to_true: Dict[str, List[int]] = {b: [] for b in Config.BANK_TARGETS}\n",
    "bank_to_pred: Dict[str, List[int]] = {b: [] for b in Config.BANK_TARGETS}\n",
    "\n",
    "# Используем DataLoader для батчинга\n",
    "eval_texts = test_df['text'].values\n",
    "eval_labels = test_df[Config.BANK_TARGETS].values\n",
    "\n",
    "# Создаём батчи\n",
    "batch_size = Config.BATCH_SIZE\n",
    "num_samples = len(eval_texts)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        batch_texts = eval_texts[start_idx:end_idx]\n",
    "        batch_labels = eval_labels[start_idx:end_idx]\n",
    "        \n",
    "        # 1.Кодируем тексты и предсказываем банки\n",
    "        batch_encoded = torch.tensor(\n",
    "            [encode_text(text) for text in batch_texts], \n",
    "            dtype=torch.long, \n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        bank_logits = banks_model(batch_encoded)\n",
    "        bank_probs = torch.sigmoid(bank_logits).cpu().numpy()  # (batch_size, num_banks)\n",
    "        \n",
    "        # Обрабатываем каждый пример в батче\n",
    "        for idx_in_batch in range(len(batch_texts)):\n",
    "            text_encoded = batch_encoded[idx_in_batch:idx_in_batch+1]  # (1, seq_len)\n",
    "            true_labels = batch_labels[idx_in_batch]\n",
    "            pred_bank_probs = bank_probs[idx_in_batch]\n",
    "            \n",
    "            # Определяем, какие банки модель нашла\n",
    "            pred_bank_idxs = np.where(pred_bank_probs >= Config.BANK_THRESHOLD)[0]  \n",
    "            \n",
    "            # 2. Для каждого найденного банка предсказываем сентимент\n",
    "            if len(pred_bank_idxs) > 0:\n",
    "                # Батчим предсказания сентимента для всех найденных банков\n",
    "                bank_idx_tensor = torch.tensor(pred_bank_idxs, dtype=torch.long, device=device)\n",
    "                text_repeated = text_encoded.repeat(len(pred_bank_idxs), 1)  # (num_banks, seq_len)\n",
    "                \n",
    "                sent_logits = sentiment_model_ba(text_repeated, bank_idx_tensor)\n",
    "                sent_preds = torch.argmax(sent_logits, dim=1).cpu().numpy()\n",
    "                \n",
    "                for bank_idx, sent_pred in zip(pred_bank_idxs, sent_preds):\n",
    "                    bank_name = Config.BANK_TARGETS[bank_idx]\n",
    "                    true_label = true_labels[bank_idx]\n",
    "                    \n",
    "                    if pd.notna(true_label):\n",
    "                        bank_to_true[bank_name].append(Config.SENTIMENT_LABELS[int(true_label)])\n",
    "                        bank_to_pred[bank_name].append(int(sent_pred))\n",
    "\n",
    "# Подсчитываем метрики\n",
    "\n",
    "per_bank_f1: Dict[str, float] = {}\n",
    "all_true: List[int] = [] \n",
    "all_pred: List[int] = []\n",
    "\n",
    "for bank_name in Config.BANK_TARGETS:\n",
    "    if len(bank_to_true[bank_name]) > 0:\n",
    "        score = f1_score(bank_to_true[bank_name], bank_to_pred[bank_name], average='macro')\n",
    "        per_bank_f1[bank_name] = float(score)\n",
    "        all_true.extend(bank_to_true[bank_name])\n",
    "        all_pred.extend(bank_to_pred[bank_name])\n",
    "        \n",
    "        print(f\"{bank_name:12s}: F1={score:.4f}, samples={len(bank_to_true[bank_name])}\")  # Дополнительно выводим количество примеров\n",
    "        \n",
    "        # Логирование в ClearML\n",
    "        log.report_single_value(f\"{bank_name}_f1\", score)\n",
    "\n",
    "    else:\n",
    "        print(f\"{bank_name:12s}: нет примеров\")\n",
    "\n",
    "# Общая метрика\n",
    "overall_macro_f1 = float(f1_score(all_true, all_pred, average='macro')) if len(all_true) > 0 else float('nan')\n",
    "\n",
    "log.report_single_value('Overall_macro_f1', overall_macro_f1)\n",
    "log.report_single_value('Total_samples', len(all_true))\n",
    "\n",
    "print(f\"\\nOverall Macro F1 = {overall_macro_f1:.4f} (N={len(all_true)} примеров)\")  # Итоговая валидационная оценка пайплайна end-to-end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bed348-8ea8-42d8-8b4f-dbba5495afef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:57:21.397764Z",
     "iopub.status.busy": "2025-10-28T15:57:21.397483Z",
     "iopub.status.idle": "2025-10-28T15:57:21.424636Z",
     "shell.execute_reply": "2025-10-28T15:57:21.423985Z",
     "shell.execute_reply.started": "2025-10-28T15:57:21.397744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Предсказания модели на реальных примерах\n",
    "\n",
    "print(\"Примеры предсказаний:\")\n",
    "\n",
    "test_examples = [\n",
    "    (\"Сбербанк - отличный банк!\", \"sber\", 1),  \n",
    "    (\"ВТБ ужасный, плохое обслуживание\", \"vtb\", -1),  \n",
    "    (\"Открыл счет в Альфа-Банке\", \"alfabank\", 0),  \n",
    "    (\"Газпромбанк хороший, рекомендую\", \"gazprom\", 1), \n",
    "    (\"Райффайзен меня разочаровал\", \"raiffeisen\", -1),  \n",
    "]  \n",
    "\n",
    "for i, (text, bank, expected) in enumerate(test_examples, 1):\n",
    "    bank_idx = Config.BANK_TARGETS.index(bank)\n",
    "    x = torch.tensor(encode_text(text), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    bank_t = torch.tensor([bank_idx], dtype=torch.long, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = sentiment_model_ba(x, bank_t)\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        pred = torch.argmax(logits, dim=1).item()\n",
    "        pred_sent = Config.LABELS_TO_SENTIMENT[pred]  # Возвращаемся из индекса в исходные {-1,0,1}\n",
    "    \n",
    "    result = \"ВЕРНО\" if pred_sent == expected else \"ОШИБКА\"\n",
    "    \n",
    "    print(f\"\\n[Пример {i}] {result}\")\n",
    "    print(f\"Текст: '{text}'\")\n",
    "    print(f\"Банк: {bank}\")\n",
    "    print(f\"Ожидалось: {expected:+d} | Получено: {pred_sent:+d}\")\n",
    "    print(f\"Вероятности: NEG={probs[0]:.3f} | NEU={probs[1]:.3f} | POS={probs[2]:.3f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nЛегенда: NEG (негативный=-1), NEU (нейтральный=0), POS (позитивный=+1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc7721-758e-47cb-af6b-91dadf04e649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T15:57:36.249731Z",
     "iopub.status.busy": "2025-10-28T15:57:36.249425Z",
     "iopub.status.idle": "2025-10-28T15:57:44.999111Z",
     "shell.execute_reply": "2025-10-28T15:57:44.998366Z",
     "shell.execute_reply.started": "2025-10-28T15:57:36.249709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Заканчиваем сессию в ClearML, чтобы зафиксировать артефакты\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
