# Sentiment Analysis of Financial News Headlines

## Описание задачи

Цель: выбор модели обучения для определения тональности текстовых фрагментов, полученных из новостных лент и комментариев, в отношении финансовых организаций и компаний, торгующихся на бирже. 

В данном проекте показаны два разных подхода к решению задачи определения банка и его сентимента. Проект основан на Kaggle соревнования "Sentiment Analysis of Financial News Headlines": https://www.kaggle.com/competitions/sentiment-analysis-of-financial-news-headlines/overview .
Непосредственно в Kaggle соревновании была представлена только версия классического ML-пайплайна. На открытом наборе данных было занято **3 место** (из 17), на приватном - 5.

В рамках  ислледования были реализованы два ноутбука:
1. 'sentiment_logreg.ipynb' - классический ML-пайплайн на TF-IDF + LogisticRegression.
2. 'sentiment-nlp.ipynb' - нейронная архитектура на PyTorch с двумя GRU.

## Данные и подготовка

Датасет взят с соревнования kaggle, но загружается из ClearML.

**Структура датасета:** CSV-файл c колонками 'id', 'text' и семью столбцами по банкам ['sber', 'vtb', 'gazprom', 'alfabank', 'raiffeisen', 'rshb', 'company']. Значения в банковских колонках - {-1, 0, 1} по тональности или 'NaN', если компания не упоминалась.
**Предварительная обработка:** заполнение пропусков в тексте, разбиение на обучающую и тестовую выборки, разведочный анализ данных.

<img width="1320" height="444" alt="image" src="https://github.com/user-attachments/assets/3e54de74-fe13-43d9-a05b-3887576eb0b8" />

<img width="1332" height="438" alt="image" src="https://github.com/user-attachments/assets/4cf6fa0d-df49-47ea-a2f6-275f593e4824" />

<p align="center">
  <img width="745" height="401" alt="image" src="https://github.com/user-attachments/assets/072c8f98-ff47-4c4b-b970-3ddcb358e89f" />
</p>

<p align="center">
  <img width="551" height="400" alt="image" src="https://github.com/user-attachments/assets/3a518311-43aa-48b3-bb14-4273a9f8cb2d" />
</p>

<p align="center">
  <img width="1297" height="361" alt="image" src="https://github.com/user-attachments/assets/e1d0fa22-1974-40cc-ad2a-63a64e98e7b0" />
</p>

## Ноутбук `1.sentiment_logreg.ipynb`

В ноутбуке реализуется базовый классический пайплайн с использованием LogisticRegression.

### Основные этапы

**Очистка текста:** удаление спецсимволов и пробелов, приведение к нижнему регистру.
**Нормализация:** токенизация, удаление стоп-слов на основе 'nltk' и лемматизация с помощью 'pymorphy2'.
**Векторизация:** TF-IDF с учётом униграмм и биграмм ('min_df=2', 'max_df=0.9').
**Создание моделей:** для каждого из семи банков строится бинарный классификатор наличия банка: TF-IDF + LogisticRegression. 
**Инференс:** для каждого текста сначала предсказывается наличие банка 'first_models_by_bank, если банк найден, вызывается классификатор тональности 'second_models_by_bank' и результаты формируются в строку с колонками {target}_n, {target}_0, {target}_p.
**Оценка:** основная метрика - macro F1.

### Итоги
Для модели определения банка macro F1 около 0.95, для определения сентимента - 0.71. Macro F усредненная по 21 колонке на тесте около 0.67.

## Ноутбук `2.sentiment-nlp.ipynb`

В ноутбуке реализуется создание двух GRU. Основная цель - повысить качество за счёт совместного решения двух задач: детекции банков и классификации тональности с учётом контекстной информации.

### Подготовка и эмбеддинги
- Обучается собственный WordPiece-токенизатор, что позволяет корректно обрабатывать финансовые термины.
- Word2Vec используется для предварительной инициализации эмбеддингов.
- Эмбеддинги дообучаются во время тренировки.

### Архитектура
1. **GRUMultiLabel:** двунаправленная GRU и линейный классификатор с 'BCEWithLogitsLoss'. Модель решает задачу детекции банков.
2. **BankAwareGRUClassifier:** двунаправленная GRU с функцией потерь — 'CrossEntropyLoss' с весами классов. Модель прогнозирует тональность текста относительно конкретного банка. 

### Обучение

- Используются оптимизаторы Adam и AdamW;
- Чекпоинты 'banks_model_best.pt' и 'sentiment_best_model.pt' сохраняются в ClearML.

**Инференс:** состоит из двух шагов: сначала предсказываются банки, затем для каждого обнаруженного банка определяется тональность.

### Итоги
Для модели определения банка macro F1 около 0.97, для определения сентимента - 0.73. Усредненная macro F1 на тестовой выборке — около 0.74.

<img width="684" height="465" alt="image" src="https://github.com/user-attachments/assets/1b169aec-5da5-4f04-964d-f83de5e2b8af" /> <img width="690" height="462" alt="image" src="https://github.com/user-attachments/assets/b0fef4d6-7262-4b94-a519-ba2ab9d4398b" />

<img width="689" height="462" alt="image" src="https://github.com/user-attachments/assets/fea09d62-8160-4ebf-a138-71b4d9a92727" /> <img width="682" height="464" alt="image" src="https://github.com/user-attachments/assets/545ad4d0-9e94-4054-bed7-68e37f39bb0b" />

## Сравнение подходов

Пайплайн c двумя нейросетями **даёт прирост качества** - детектор банков 0.97 против 0.95, сентимент 0.73 против 0.71, итоговая macro F1 0.74 против 0.67, т.е. **нейросеть лучше извлекает контекст и связки текст–банк**. При этом, если анализировать с точки зрения реализации, то подход TF-IDF + LogisticRegression работает **быстрее и требует минимальной инфраструктуры**, а нейронные сети **сложнее** (обучение WordPiece, Word2Vec, две GRU, настройка оптимизаторов).
Задача сентимент-анализа финансовых текстов в данном случае является сложной из‑за дисбаланса классов и сложных языковых конструкций, поэтому простые методы вроде TF-IDF и логистической регрессии подходят как базовый ориентир (для быстрой работы при ограниченных ресурсах), тогда как полноценный нейронный пайплайн с токенизацией, эмбеддингами и GRU-моделями лучше преодолевает ограничения данных и даёт заметно более высокое качество, поэтому предпочтительнее в данном случае выбрать второй подход (при условии,что есть возможность поддерживать такую модель).

