# Sentiment Analysis of Financial News Headlines

## Описание задачи

Цель: выбор модели обучения для определения тональности текстовых фрагментов, полученных из новостных лент и комментариев, в отношении финансовых организаций и компаний, торгующихся на бирже. 

В данном проекте показаны два разных подхода к решению задачи определения банка и его сентимента. Проект основан на Kaggle соревнования "Sentiment Analysis of Financial News Headlines": https://www.kaggle.com/competitions/sentiment-analysis-of-financial-news-headlines/overview
Непосредственно в Kaggle соревновании была представлена только версия классического ML-пайплайна. На открытом наборе данных было занято **3 место** (из 17), на приватном - 5.

В рамках  ислледования были реализованы два ноутбука:
1. 'sentiment_logreg.ipynb' - классический ML-пайплайн на TF-IDF + LogisticRegression.
2. 'sentiment-nlp.ipynb' - нейронная архитектура на PyTorch с двумя GRU.

## Данные и подготовка

Датасет взят с соревнования kaggle, но загружается из ClearML.

**Структура датасета:** CSV-файл c колонками 'id', 'text' и семью столбцами по банкам ['sber', 'vtb', 'gazprom', 'alfabank', 'raiffeisen', 'rshb', 'company']. Значения в банковских колонках - {-1, 0, 1} по тональности или 'NaN', если компания не упоминалась.
**Предварительная обработка:** заполнение пропусков в тексте, разбиение на обучающую и тестовую выборки, разведочный анализ данных.

!!! графики данных

## Ноутбук `1. sentiment_logreg.ipynb`

В ноутбуке реализуется базовый классический пайплайн с использованием LogisticRegression.

### Основные этапы

**Очистка текста:** удаление спецсимволов и пробелов, приведение к нижнему регистру.
**Нормализация:** токенизация, удаление стоп-слов на основе 'nltk' и лемматизация с помощью 'pymorphy2'.
**Векторизация:** TF-IDF с учётом униграмм и биграмм ('min_df=2', 'max_df=0.9').
**Моделирование:** для каждого из семи банков строится бинарный классификатор наличия банка: TF-IDF + LogisticRegression. 
**Инференс:** для каждого текста сначала предсказывается наличие банка 'first_models_by_bank, если банк найден, вызывается классификатор тональности 'second_models_by_bank' и результаты формируются в строку с колонками {target}_n, {target}_0, {target}_p.
**Оценка:** основная метрика - macro F1.

### Итоги
Для модели определения банка macro F1 около 0.95, для определения сентимента - 0.71. Macro F усредненная по 21 колонке на тесте около 0.67.

!график из клирмл

## Ноутбук `2. sentiment-nlp.ipynb`

End-to-end пайплайн. Основная цель - повысить качество за счёт совместного решения двух задач: детекции банков и классификации тональности с учётом контекстной информации.

### Подготовка и эмбеддинги
- Обучается собственный WordPiece-токенизатор, что позволяет корректно обрабатывать финансовые термины.
- Word2Vec используется для предварительной инициализации эмбеддингов.
- Эмбеддинги дообучаются во время тренировки, что повышает адаптацию к задаче.

### Архитектура
1. **GRUMultiLabel:** двунаправленная GRU и линейный классификатор с 'BCEWithLogitsLoss'. Модель решает задачу детекции банков.
2. **BankAwareGRUClassifier:** двунаправленная GRU с функцией потерь — 'CrossEntropyLoss' с весами классов. Модель прогнозирует тональность текста относительно конкретного банка. 

**Обучение:**
- Используются оптимизаторы Adam и AdamW;
- Чекпоинты 'banks_model_best.pt' и 'sentiment_best_model.pt' сохраняются в ClearML.
**Инференс:** состоит из двух шагов: сначала предсказываются банки, затем для каждого обнаруженного банка определяется тональность.

### Итоги
Для модели определения банка macro F1 около 0.97, для определения сентимента - 0.73. Усредненная macro F1 на тестовой выборке — около 0.74.

## Сравнение подходов

End-to-end пайплайн c двумя нейросетями **даёт прирост качества** - детектор банков 0.97 против 0.95, сентимент 0.73 против 0.71, итоговая macro F1 0.74 против 0.67, т.е. **нейросеть лучше извлекает контекст и связки текст–банк**. При этом, если анализировать с точки зрения реализации, то подход TF-IDF + LogisticRegression работает **быстрее и требует минимальной инфраструктуры**, а нейронной сети **сложнее** (обучение WordPiece, Word2Vec, две GRU, настройка оптимизаторов).
Задача сентимент-анализа финансовых текстов в данном случае является сложной из‑за дисбаланса классов и сложных языковых конструкций, поэтому простые методы вроде TF-IDF и логистической регрессии подходят как базовый ориентир (для быстрой работы при ограниченных ресурсах), тогда как полноценный нейронный пайплайн с токенизацией, эмбеддингами и GRU-моделями лучше преодолевает ограничения данных и даёт заметно более высокое качество, поэтому предпочтительнее в данном выбрать второй подход, если есть возможность поддерживать такую модель.

