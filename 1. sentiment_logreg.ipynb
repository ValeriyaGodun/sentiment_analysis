{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180442f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:13:14.832445Z",
     "iopub.status.busy": "2024-06-08T13:13:14.831973Z",
     "iopub.status.idle": "2024-06-08T13:13:49.329878Z",
     "shell.execute_reply": "2024-06-08T13:13:49.328610Z"
    },
    "papermill": {
     "duration": 34.517105,
     "end_time": "2024-06-08T13:13:49.339393",
     "exception": false,
     "start_time": "2024-06-08T13:13:14.822288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Устанавливаем дополнительные библиотеки, которых нет в стандартной среде Kaggle\n",
    "!pip install clearml\n",
    "!pip install pymorphy2\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b747dc-a339-4810-9fe3-ec812432d0e5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Настраиваем окружение ClearML\n",
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=''\n",
    "%env CLEARML_API_SECRET_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82eedb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:13:49.358228Z",
     "iopub.status.busy": "2024-06-08T13:13:49.357795Z",
     "iopub.status.idle": "2024-06-08T13:13:50.285508Z",
     "shell.execute_reply": "2024-06-08T13:13:50.284521Z"
    },
    "papermill": {
     "duration": 0.94023,
     "end_time": "2024-06-08T13:13:50.288259",
     "exception": false,
     "start_time": "2024-06-08T13:13:49.348029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки\n",
    "import pandas as pd\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from clearml import Task, Logger, Dataset  # Интеграция с ClearML для отслеживания экспериментов и управления датасетами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd0b91-5145-460f-87f0-9348b2cc8a12",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Находим датасет в clear ml и скачиваем его в кэш \n",
    "dataset = Dataset.get('2a542c96a0de46b0bc8b4977bf536180')\n",
    "print(dataset.list_files())\n",
    "\n",
    "local_path = dataset.get_local_copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0eec0-6b21-49df-9074-69273aa72491",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Читаем обучающую выборку\n",
    "orig_df = pd.read_csv(f'{local_path}/train.csv',sep=\";\",quoting=csv.QUOTE_NONE, na_values=['NULL'])\n",
    "\n",
    "# Пропуски в тексте заменяем пустой строкой, чтобы облегчить дальнейшую обработку\n",
    "orig_df['text'] = orig_df['text'].fillna('')\n",
    "orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114071d-473d-4a4f-b57a-71e4a7308416",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Разбиваем на train/test\n",
    "train_df, test_df = train_test_split(\n",
    "    orig_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c1892-d1ce-4dc5-b46f-94e4e210869b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Инициализируем удаленную таску\n",
    "task = Task.init(\n",
    "        project_name=\"sentiment_analysis_kaggle_mllabs\",\n",
    "        task_name=\"baseline_tfidf_lr\",\n",
    "        task_type=\"training\",\n",
    ")\n",
    "task:Task\n",
    "\n",
    "# Получаем объект логгера, чтобы писать ключевые метрики в ClearML\n",
    "log = Logger.current_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4e715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:13:50.431328Z",
     "iopub.status.busy": "2024-06-08T13:13:50.430926Z",
     "iopub.status.idle": "2024-06-08T13:13:50.437319Z",
     "shell.execute_reply": "2024-06-08T13:13:50.436235Z"
    },
    "papermill": {
     "duration": 0.018582,
     "end_time": "2024-06-08T13:13:50.439811",
     "exception": false,
     "start_time": "2024-06-08T13:13:50.421229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Работаем с копией, чтобы при необходимости вернуться к оригинальному train_df без перезапуска ноутбука\n",
    "main_train_df = deepcopy(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375df825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполняем лемматизацию и препроцессинг\n",
    "patterns = re.compile(\"[0-9!#$%&'()*+,./:;<=>?[\\\\]^_`{|}~—\\\\\\\"\\\\-]+\")  # Фильтруем цифры и знаки пунктуации, оставляя только полезные токены\n",
    "stopwords_ru = set(stopwords.words(\"russian\"))  # Ограничиваемся русским списком стоп-слов, чтобы не терять семантику\n",
    "morph = MorphAnalyzer()  # Морфологический анализатор для нормализации словоформ\n",
    "\n",
    "_cache = {}\n",
    "\n",
    "def lemmatize(doc: str) -> str:\n",
    "    if not isinstance(doc, str):\n",
    "        return \"\"\n",
    "    if doc in _cache:\n",
    "        return _cache[doc]\n",
    "    clean = patterns.sub(\" \", doc.lower())  # Приводим к нижнему регистру, чтобы TF-IDF не раздувал словарь\n",
    "    tokens = []\n",
    "    for token in clean.split():\n",
    "        if token and token not in stopwords_ru:\n",
    "            lemma = morph.normal_forms(token)[0]\n",
    "            tokens.append(lemma)\n",
    "    res = \" \".join(tokens)\n",
    "    _cache[doc] = res\n",
    "    return res\n",
    "\n",
    "main_train_df = deepcopy(train_df)\n",
    "main_train_df['text'] = main_train_df['text'].apply(lemmatize)\n",
    "main_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d716fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:14:10.690820Z",
     "iopub.status.busy": "2024-06-08T13:14:10.690383Z",
     "iopub.status.idle": "2024-06-08T13:14:10.836026Z",
     "shell.execute_reply": "2024-06-08T13:14:10.834602Z"
    },
    "papermill": {
     "duration": 0.158717,
     "end_time": "2024-06-08T13:14:10.838647",
     "exception": false,
     "start_time": "2024-06-08T13:14:10.679930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = ['sber', 'vtb', 'gazprom', 'alfabank', 'raiffeisen', 'rshb', 'company']\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45b426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:14:10.858537Z",
     "iopub.status.busy": "2024-06-08T13:14:10.858114Z",
     "iopub.status.idle": "2024-06-08T13:14:10.883927Z",
     "shell.execute_reply": "2024-06-08T13:14:10.882923Z"
    },
    "papermill": {
     "duration": 0.038889,
     "end_time": "2024-06-08T13:14:10.886599",
     "exception": false,
     "start_time": "2024-06-08T13:14:10.847710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "first_df = deepcopy(main_train_df)\n",
    "for target in targets:\n",
    "    first_df[target] = first_df[target].replace(0,1).replace(-1,1).fillna(0).astype(int)\n",
    "first_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98889726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение детекторов компаний: TF-IDF + LogisticRegression\n",
    "\n",
    "first_models_by_bank = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for target in targets:\n",
    "    y = first_df[target].astype(int)\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=2, sublinear_tf=True)),  # Генерируем уни- и биграммы, ограничивая редкие/частые нграммы\n",
    "        (\"clf\", LogisticRegression(class_weight=\"balanced\", max_iter=1000, solver=\"liblinear\"))  # Балансируем классы, т.к. негативных примеров значительно меньше\n",
    "    ])\n",
    "    param_grid = {\"clf__C\": [0.5, 1.0, 2.0]}\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=cv, n_jobs=-1, scoring=\"f1\")\n",
    "    grid.fit(first_df[\"text\"], y)\n",
    "    print(f\"{target}: best CV f1={grid.best_score_:.3f}, params={grid.best_params_}\")\n",
    "    \n",
    "    # ClearML logging\n",
    "    log.report_scalar(title=f\"detector_{target}\", series=\"best_f1\", value=grid.best_score_, iteration=0)\n",
    "    log.report_single_value(f\"{target} best params: {grid.best_params_}\")\n",
    "\n",
    "    first_models_by_bank[target] = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение классификаторов сентимента: TF-IDF + LogisticRegression\n",
    "second_models_by_bank = {}\n",
    "\n",
    "for target in targets:\n",
    "    second_df = main_train_df.loc[main_train_df[target].notnull()][['id','text', target]]\n",
    "    y = second_df[target].astype(int)\n",
    "    pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=2, sublinear_tf=True)),  # Используем ту же текстовую схему, чтобы сравнение метрик было честным\n",
    "        (\"clf\", LogisticRegression(solver='lbfgs', multi_class='multinomial', class_weight='balanced', max_iter=1000))  # Мультином. логистическая регрессия позволяет одновременно предсказывать три класса {-1,0,1}\n",
    "    ])\n",
    "    param_grid = {\"clf__C\": [0.5, 1.0, 2.0]}\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=cv, n_jobs=-1, scoring=\"f1_macro\") \n",
    "    grid.fit(second_df['text'], y)\n",
    "    print(f\"{target}: best CV f1_macro={grid.best_score_:.3f}, params={grid.best_params_}\")\n",
    "    \n",
    "    # ClearML logging\n",
    "    log.report_scalar(title=f\"sentiment_{target}\", series=\"best_f1_macro\", value=grid.best_score_, iteration=0)\n",
    "    log.report_single_value(f\"{target} sentiment best params: {grid.best_params_}\")\n",
    "\n",
    "    second_models_by_bank[target] = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70e220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T13:24:22.596364Z",
     "iopub.status.busy": "2024-06-08T13:24:22.595935Z",
     "iopub.status.idle": "2024-06-08T13:24:22.614578Z",
     "shell.execute_reply": "2024-06-08T13:24:22.613471Z"
    },
    "papermill": {
     "duration": 0.032808,
     "end_time": "2024-06-08T13:24:22.617158",
     "exception": false,
     "start_time": "2024-06-08T13:24:22.584350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Пример для проверки определения банков\n",
    "text_sample = [lemmatize('RT @alfa_bank: @grey_winged Банк гарантирует отправку смс, опос отвечает за доставку. К сожалению, мы не можем повлиять на сроки решения пр')]\n",
    "first_models_by_bank[\"alfabank\"].predict(text_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99191941",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T14:48:21.663313Z",
     "iopub.status.busy": "2024-06-08T14:48:21.662831Z",
     "iopub.status.idle": "2024-06-08T14:48:21.676055Z",
     "shell.execute_reply": "2024-06-08T14:48:21.674867Z"
    },
    "papermill": {
     "duration": 0.029629,
     "end_time": "2024-06-08T14:48:21.678391",
     "exception": false,
     "start_time": "2024-06-08T14:48:21.648762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Пример для проверки эмоциональной окраски\n",
    "text_sample = [lemmatize('Опять «порадовал» @sberbank Платёжка получена банком в 15:28 и так и не проведена. Ну никак не хотят работать!')]\n",
    "second_models_by_bank[\"sber\"].predict(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772576ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T14:48:21.842467Z",
     "iopub.status.busy": "2024-06-08T14:48:21.841943Z",
     "iopub.status.idle": "2024-06-08T14:48:35.035308Z",
     "shell.execute_reply": "2024-06-08T14:48:35.034134Z"
    },
    "papermill": {
     "duration": 13.21037,
     "end_time": "2024-06-08T14:48:35.038238",
     "exception": false,
     "start_time": "2024-06-08T14:48:21.827868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Делаем копию тестовой части и прогоняем через тот же препроцессинг, что и train\n",
    "main_test_df = deepcopy(test_df)\n",
    "main_test_df['text'] = main_test_df['text'].apply(lemmatize)\n",
    "\n",
    "for target in targets: \n",
    "    # Здесь повторяем бинаризацию меток\n",
    "    main_test_df[target] = main_test_df[target].replace(0,1).replace(-1,1).fillna(0).astype(int)\n",
    "\n",
    "main_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f83112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T14:48:35.065439Z",
     "iopub.status.busy": "2024-06-08T14:48:35.064349Z",
     "iopub.status.idle": "2024-06-08T14:48:40.640397Z",
     "shell.execute_reply": "2024-06-08T14:48:40.639177Z"
    },
    "papermill": {
     "duration": 5.592441,
     "end_time": "2024-06-08T14:48:40.643235",
     "exception": false,
     "start_time": "2024-06-08T14:48:35.050794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Финальный инференс: сначала определяем банки, затем определяем тональность\n",
    "res = []\n",
    "\n",
    "for _, test_row in main_test_df.iterrows():\n",
    "    text_sample = [test_row[\"text\"]]\n",
    "    res_row = {\"id\": test_row[\"id\"]}\n",
    "\n",
    "    for target in targets:\n",
    "        for postfix in ['n','0','p']:\n",
    "            res_row[f\"{target}_{postfix}\"] = 0\n",
    "\n",
    "        det = first_models_by_bank[target].predict(text_sample)[0]\n",
    "        if det == 1:\n",
    "            prediction = second_models_by_bank[target].predict(text_sample)[0]\n",
    "            if prediction == -1:\n",
    "                res_row[f\"{target}_n\"] = 1\n",
    "            elif prediction == 0:\n",
    "                res_row[f\"{target}_0\"] = 1\n",
    "            elif prediction == 1:\n",
    "                res_row[f\"{target}_p\"] = 1\n",
    "\n",
    "    res.append(res_row)\n",
    "\n",
    "all_cols = [f\"{t}_{p}\" for t in targets for p in ['n','0','p']]\n",
    "pred_test_df = pd.DataFrame(res)\n",
    "pred_test_df = pred_test_df.merge(main_test_df[['id']], on='id', how='right')  # merge гарантирует сохранение порядка id\n",
    "pred_test_df = pred_test_df[['id'] + all_cols]\n",
    "Y_pred = pred_test_df[all_cols].fillna(0).astype(int).values\n",
    "\n",
    "# Формируем Y_true из оригинальных меток в test_df\n",
    "y_true_rows = []\n",
    "for _, r in test_df.iterrows():\n",
    "    row = {c: 0 for c in all_cols}\n",
    "    for target in targets:\n",
    "        val = r[target]\n",
    "        if pd.isna(val):\n",
    "            continue\n",
    "        if val == -1:\n",
    "            row[f\"{target}_n\"] = 1\n",
    "        elif val == 0:\n",
    "            row[f\"{target}_0\"] = 1\n",
    "        elif val == 1:\n",
    "            row[f\"{target}_p\"] = 1\n",
    "    y_true_rows.append(row)\n",
    "\n",
    "y_true_df = pd.DataFrame(y_true_rows)\n",
    "y_true_df = pd.concat([test_df[['id']].reset_index(drop=True), y_true_df], axis=1)\n",
    "y_true_df = y_true_df.merge(pred_test_df[['id']], on='id', how='right')\n",
    "Y_true = y_true_df[all_cols].fillna(0).astype(int).values\n",
    "\n",
    "col_f1 = [f1_score(Y_true[:, i], Y_pred[:, i], zero_division=0) for i in range(len(all_cols))]  # Считаем метрику по каждому «банк+тональность»\n",
    "test_macro_f1_21 = float(np.mean(col_f1))  # Сводим в усреднённую метрику\n",
    "\n",
    "log.report_scalar(title=\"test_macro_f1_21cols\", series=\"macro_f1\", value=test_macro_f1_21, iteration=0)\n",
    "log.report_text(f\"Per-column F1 (test): {dict(zip(all_cols, [float(x) for x in col_f1]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a94fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим столбчатую диаграмму F1 по каждому признаку и логгируем в ClearML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(all_cols, col_f1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('F1 per column (test)')\n",
    "plt.tight_layout()\n",
    "log.report_matplotlib_figure(title='test_f1', series='f1_bar', iteration=0, figure=plt.gcf())  # Логируем график в ClearML\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612bda49-cced-450f-8164-e38021eeb40e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Закрываем задачу, чтобы ClearML корректно сохранил артефакты\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8070629,
     "sourceId": 72640,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5729.834854,
   "end_time": "2024-06-08T14:48:41.603178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-08T13:13:11.768324",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
